{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "정수 인코딩(Integer Encoding).ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOs2MDih0jRwBnrXoJvsCzU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gksrbans/NLP-Wiki/blob/main/%EC%A0%95%EC%88%98_%EC%9D%B8%EC%BD%94%EB%94%A9(Integer_Encoding).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHe3kXRJ1MEw"
      },
      "source": [
        "# 단어의 갯수만큼 1번부터 그 길이까지 고유한 정수번호에 맵핑 시키는 작업.\n",
        "# ex) book은 151번, love는 192번 ...\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fe1fAJFh9Iub"
      },
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "raw_text = \"A barber is a person. a barber is good person. a barber is huge person. he Knew A Secret! The Secret He Kept is huge secret. Huge secret. His barber kept his word. a barber kept his word. His barber kept his secret. But keeping and keeping such a huge secret to himself was driving the barber crazy. the barber went up a huge mountain.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-giimfJ9UwI",
        "outputId": "3fadaddd-8f24-4f91-efcf-d6b7ddeec0a1"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTT0SS-a9OYf",
        "outputId": "b31dcaf5-c65c-430d-ef84-2474808bc820"
      },
      "source": [
        "# 문장 토큰화\n",
        "sentences = sent_tokenize(raw_text)\n",
        "print(sentences)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['A barber is a person.', 'a barber is good person.', 'a barber is huge person.', 'he Knew A Secret!', 'The Secret He Kept is huge secret.', 'Huge secret.', 'His barber kept his word.', 'a barber kept his word.', 'His barber kept his secret.', 'But keeping and keeping such a huge secret to himself was driving the barber crazy.', 'the barber went up a huge mountain.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zb7ZaLX69raq",
        "outputId": "14ea5eed-b486-4f66-b8ef-cbf0412d2296"
      },
      "source": [
        "vocab = {}\n",
        "preprocessed_sentences = []\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "for sentence in sentences:\n",
        "  #문장 -> 단어로\n",
        "  tokenized_sentence = word_tokenize(sentence)\n",
        "  result = []\n",
        "\n",
        "  for word in tokenized_sentence:\n",
        "    word = word.lower()\n",
        "    if word not in stop_words: #불용어에 없을 경우\n",
        "      if len(word) > 2:\n",
        "        result.append(word)\n",
        "        if word not in vocab:\n",
        "          vocab[word] = 0\n",
        "        vocab[word] += 1\n",
        "\n",
        "  preprocessed_sentences.append(result)\n",
        "print(preprocessed_sentences)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['barber', 'person'], ['barber', 'good', 'person'], ['barber', 'huge', 'person'], ['knew', 'secret'], ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'], ['barber', 'kept', 'word'], ['barber', 'kept', 'word'], ['barber', 'kept', 'secret'], ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'], ['barber', 'went', 'huge', 'mountain']]\n"
          ]
        }
      ]
    }
  ]
}